#!/usr/bin/env python
"""
Script de diagn√≥stico para verificar Ollama y el modelo configurado
"""
import requests
import json
import os
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

OLLAMA_BASE_URL = os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434')
OLLAMA_MODEL = os.getenv('OLLAMA_MODEL', 'qwen2.5:3b-instruct-q4_K_M')

print("=" * 60)
print("DIAGN√ìSTICO DE OLLAMA")
print("=" * 60)
print(f"\nüì° URL de Ollama: {OLLAMA_BASE_URL}")
print(f"ü§ñ Modelo configurado: {OLLAMA_MODEL}\n")

# 1. Verificar si Ollama est√° corriendo
print("1Ô∏è‚É£ Verificando conexi√≥n con Ollama...")
try:
    response = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=5)
    if response.status_code == 200:
        print("   ‚úÖ Ollama est√° corriendo")
        models = response.json().get('models', [])
        print(f"   üì¶ Modelos instalados: {len(models)}")
        
        # 2. Verificar si el modelo est√° instalado
        print(f"\n2Ô∏è‚É£ Verificando si el modelo '{OLLAMA_MODEL}' est√° instalado...")
        model_names = [model.get('name', '') for model in models]
        model_available = any(OLLAMA_MODEL in name for name in model_names)
        
        if model_available:
            print(f"   ‚úÖ Modelo '{OLLAMA_MODEL}' est√° instalado")
            # Mostrar el nombre exacto
            exact_match = [name for name in model_names if OLLAMA_MODEL in name]
            if exact_match:
                print(f"   üìù Nombre exacto: {exact_match[0]}")
        else:
            print(f"   ‚ùå Modelo '{OLLAMA_MODEL}' NO est√° instalado")
            print(f"\n   üí° Para instalarlo, ejecuta:")
            print(f"      ollama pull {OLLAMA_MODEL}")
            
            # Mostrar modelos similares
            print(f"\n   üìã Modelos disponibles similares:")
            similar = [name for name in model_names if 'qwen' in name.lower() or '3b' in name.lower()]
            for name in similar[:5]:
                print(f"      - {name}")
        
        # 3. Listar todos los modelos
        print(f"\n3Ô∏è‚É£ Todos los modelos instalados:")
        if models:
            for model in models:
                name = model.get('name', 'N/A')
                size = model.get('size', 0)
                size_gb = size / (1024**3) if size > 0 else 0
                print(f"   - {name} ({size_gb:.2f} GB)")
        else:
            print("   ‚ö†Ô∏è No hay modelos instalados")
            
    else:
        print(f"   ‚ùå Ollama respondi√≥ con c√≥digo {response.status_code}")
        
except requests.exceptions.ConnectionError:
    print("   ‚ùå No se pudo conectar con Ollama")
    print(f"\n   üí° Aseg√∫rate de que Ollama est√© ejecut√°ndose:")
    print(f"      - En Windows: Abre la aplicaci√≥n Ollama")
    print(f"      - Verifica que est√© en: {OLLAMA_BASE_URL}")
    
except Exception as e:
    print(f"   ‚ùå Error: {str(e)}")

print("\n" + "=" * 60)
print("FIN DEL DIAGN√ìSTICO")
print("=" * 60)

